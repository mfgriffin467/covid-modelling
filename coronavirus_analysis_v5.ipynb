{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coronavirus data prep & modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Outstanding tasks:\n",
    " - refactor code for iloc issue with aggregations\n",
    " - check country aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "from scipy.integrate import odeint\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "df_deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")\n",
    "df_recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\")\n",
    "world_pop = pd.read_csv(\"data_feeds/population_world_data.csv\", encoding='latin-1')\n",
    "hosp_beds = pd.read_csv(\"data_feeds/hospital_beds.csv\").drop(['country'], axis=1)\n",
    "oxford = pd.read_csv(\"data_feeds/OxCGRT_Download_latest_data.csv\",parse_dates = ['Date'], encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposed and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and merge datasets\n",
    "\n",
    "latest_date = df_cases.columns[-1]\n",
    "oxford['country_map'] = oxford['CountryName'].apply(lambda x: 'Korea, South' if x == 'South Korea' else 'US' if x == 'United States' else x)\n",
    "oxford = oxford[['CountryName', 'country_map','Date','StringencyIndex']]\n",
    "world_pop['country_map'] = world_pop['Country'].apply(lambda x: 'Korea, South' if x == 'South Korea' else 'US' if x == 'United States' else x)\n",
    "df_merge = df_cases.merge(world_pop[['country_map', 'Population_2020']], how='left', left_on='Country/Region', right_on='country_map')\n",
    "df_merge = df_merge.merge(hosp_beds, how='left', left_on='Country/Region', right_on='country_map')\n",
    "df_merge['hospital_beds'] = df_merge['Population_2020'] * df_merge['hospital_beds_per_10000'] / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_transpose(df):\n",
    "    df2 = df.drop(['Province/State','Lat','Long'],axis=1).groupby(['Country/Region']).sum()\n",
    "    df3 = df2.reset_index().T\n",
    "    df3.columns = df3.iloc[0]\n",
    "    df3.drop(df3.index[0], inplace=True)\n",
    "    df3.index.rename('date', inplace=True)\n",
    "    df3.reset_index(inplace=True)    \n",
    "    df3['date'] = df3.date.apply(lambda x: parser.parse(x))\n",
    "    df3.set_index('date', inplace=True)\n",
    "    df3 = df3.apply(pd.to_numeric)\n",
    "    df3.reset_index(inplace=True)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_melting(df, var):\n",
    "    df2 = pd.melt(df, id_vars=['date'], value_vars = df.columns.drop('date'),var_name='country', value_name=var)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose all feeds\n",
    "df_t_cases = df_transpose(df_cases)\n",
    "df_t_deaths = df_transpose(df_deaths)\n",
    "df_t_recovered = df_transpose(df_recovered)\n",
    "\n",
    "# Combine country columns to index\n",
    "df_t_cases = df_melting(df_t_cases, 'actual_cases')\n",
    "df_t_deaths = df_melting(df_t_deaths, 'actual_deaths')\n",
    "df_t_recovered = df_melting(df_t_recovered, 'actual_recovered')\n",
    "\n",
    "# Merge datasets\n",
    "df_comb = df_t_cases.merge(df_t_deaths, on = ['date', 'country'], how='left')\n",
    "df_comb = df_comb.merge(df_t_recovered, on = ['date', 'country'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "\n",
    "df_comb = df_comb.merge(world_pop[['country_map', 'Population_2020']], how='left', left_on='country', right_on='country_map')\n",
    "df_comb = df_comb.merge(hosp_beds, how='left', on='country_map')\n",
    "df_comb.merge(oxford, how='left', left_on =['country_map','date'], right_on=['CountryName', 'Date'])\n",
    "df_comb['hospital_beds'] = df_comb['Population_2020'] * df_comb['hospital_beds_per_10000'] / 10000\n",
    "df_comb['fatality_rate'] = (df_comb['actual_deaths']/df_comb['actual_cases']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters, based on https://drive.google.com/file/d/1DqfSnlaW6N3GBc5YKyBOCGPfdqOsqk1G/view\n",
    "\n",
    "gamma = 1./10          # Mean period while contagious\n",
    "hosp_rate = 0.05       # 5% hospitalisation rate\n",
    "icu_rate = 0.025       # 2.5% ICU rate\n",
    "fr = 0.01/10           # Per day fatality rate\n",
    "test_multiplier = 10   # Assumed multiplier for unconfirmed cases\n",
    "start_date_dt = date(month = 3,day = 1,year = 2020)\n",
    "time_window = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple SIR model\n",
    "\n",
    "t = np.linspace(0, time_window, time_window)\n",
    "def deriv(y, t, N, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I / N\n",
    "    dIdt = beta * S * I / N - gamma * I #- fr * I \n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning:\n",
      "\n",
      "Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and 'the values will not compare equal to the\n",
      "'datetime.date'. To retain the current behavior, convert the\n",
      "'datetime.date' to a datetime with 'pd.Timestamp'.\n",
      "\n",
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning:\n",
      "\n",
      "Comparing Series of datetimes with 'datetime.date'.  Currently, the\n",
      "'datetime.date' is coerced to a datetime. In the future pandas will\n",
      "not coerce, and 'the values will not compare equal to the\n",
      "'datetime.date'. To retain the current behavior, convert the\n",
      "'datetime.date' to a datetime with 'pd.Timestamp'.\n",
      "\n",
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\scipy\\integrate\\odepack.py:247: ODEintWarning:\n",
      "\n",
      "Excess accuracy requested (tolerances too small). Run with full_output = 1 to get quantitative information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run projectionloop\n",
    "\n",
    "projections = pd.DataFrame()\n",
    "\n",
    "for ctry in df_cases[['Country/Region', latest_date]].sort_values(by=latest_date, ascending=False).head(30)['Country/Region'].unique():\n",
    "    for beta in np.linspace(0.05,0.30,11):\n",
    "        for max_pop in [0.2,0.5,0.8]:\n",
    "\n",
    "            t = np.linspace(0, time_window, time_window+1)\n",
    "\n",
    "            I0 = test_multiplier * df_comb[(df_comb['country'] == ctry) & (df_comb['date'] == start_date_dt)].actual_cases.values[0]\n",
    "            R0 = df_comb[(df_comb['country'] == ctry) & (df_comb['date'] == start_date_dt)].actual_recovered.values[0]\n",
    "            N = max_pop * df_merge[df_merge['Country/Region'] == ctry]['Population_2020'].iloc[0]\n",
    "            S0 = N - I0 - R0\n",
    "            y0 = S0, I0, R0\n",
    "            ret = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "            S, I, R = ret.T\n",
    "\n",
    "            H = I * hosp_rate\n",
    "            ICU = I * icu_rate\n",
    "            D = I * fr\n",
    "            fatalities = D.cumsum()\n",
    "            beds = np.repeat(df_merge[df_merge['Country/Region'] == ctry]['hospital_beds'].iloc[0], time_window+1)\n",
    "\n",
    "            # Output results\n",
    "            new = pd.DataFrame(data=np.array([t,S,I,R,H,ICU,D,fatalities,beds]).T, \n",
    "                                   columns=['days','projected_susceptible','projected_infections','projected_recovered','projected_hospitalisation',\n",
    "                                           'projected_icu','projected_deaths','projected_fatalities','projected_beds'])\n",
    "            new['country'] = ctry\n",
    "            new['max_pop'] = max_pop\n",
    "            new['beta'] = beta\n",
    "            projections = pd.concat([projections,new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173217, 23)\n",
      "(173217, 23)\n"
     ]
    }
   ],
   "source": [
    "# Filter for X countries with most cases\n",
    "\n",
    "ctry_list = df_cases[['Country/Region', latest_date]].sort_values(by=latest_date, ascending=False).head(50)['Country/Region'].unique()\n",
    "projections['date'] = pd.to_datetime(projections.days.apply(lambda x: start_date_dt + timedelta(x)))\n",
    "df_final = projections.merge(df_comb, how='left', on=['country','date'])\n",
    "print(df_final.shape)\n",
    "df_final[df_final['country'].isin(ctry_list)]\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new fields\n",
    "\n",
    "df_final['new_cases'] = (df_final['actual_cases'] - df_final['actual_cases'].shift(periods=1))#.fillna(0)\n",
    "df_final['new_deaths'] = (df_final['actual_deaths'] - df_final['actual_deaths'].shift(periods=1))#.fillna(0)\n",
    "df_final = df_final.merge(oxford, how='left', left_on =['country','date'], right_on=['country_map', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel regression - take logs of case numbers and dummify country\n",
    "\n",
    "df_final['projections_flag'] = df_final['actual_cases'].isna()\n",
    "df_final['ln_actual_cases'] = np.log(1+ df_final['actual_cases'])\n",
    "df_cut = df_final[(df_final.beta == 0.2) & (df_final.max_pop == 0.5)][['days','country','ln_actual_cases']]\n",
    "countries = pd.get_dummies(df_cut['country']).iloc[:, :-1]\n",
    "df = pd.concat([df_cut, countries], axis=1).drop(['country'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725, 29) (29, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split train and test sets\n",
    "\n",
    "df_train = df[df['days'] <= 24 ]\n",
    "df_test = df[(df['days'] > 24) & (df['days'] <= 25)]\n",
    "\n",
    "y_train = df_train['ln_actual_cases']\n",
    "y_test = df_test['ln_actual_cases']\n",
    "\n",
    "df_train.drop('ln_actual_cases', axis=1, inplace=True)\n",
    "df_test.drop('ln_actual_cases', axis=1, inplace=True)\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9286465449020184\n",
      "test score: 0.2654051273057976\n"
     ]
    }
   ],
   "source": [
    "# Fit regression model\n",
    "\n",
    "lr = LinearRegression(n_jobs=-1,fit_intercept = True)\n",
    "lr.fit(df_train, y_train)\n",
    "print(\"train score: \" + str(lr.score(df_train, y_train)))\n",
    "print(\"test score: \" + str(lr.score(df_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days : 0.2261\n",
      "Australia : -1.1711\n",
      "Austria : -0.6461\n",
      "Belgium : -0.6535\n",
      "Brazil : -2.1073\n",
      "Canada : -1.226\n",
      "Chile : -2.8834\n",
      "China : 4.7202\n",
      "Czechia : -1.8793\n",
      "Denmark : -1.1785\n",
      "Ecuador : -2.6839\n",
      "France : 1.3216\n",
      "Germany : 1.4308\n",
      "Iran : 2.5233\n",
      "Ireland : -2.267\n",
      "Israel : -1.7158\n",
      "Italy : 3.0201\n",
      "Japan : -0.1162\n",
      "Korea, South : 2.3201\n",
      "Luxembourg : -3.0733\n",
      "Malaysia : -1.0581\n",
      "Netherlands : -0.2747\n",
      "Norway : -0.3982\n",
      "Portugal : -1.9577\n",
      "Spain : 1.4318\n",
      "Sweden : -0.565\n",
      "Switzerland : 0.2192\n",
      "Turkey : -3.9503\n",
      "US : 1.1093\n"
     ]
    }
   ],
   "source": [
    "# Output model coefficients\n",
    "\n",
    "for i in range(0,len(df_train.columns)):\n",
    "    print(df_train.columns[i] + \" : \" + str(round(lr.coef_[i],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ln_log_reg_preds'] = lr.predict(df.drop(['ln_actual_cases'], axis=1))\n",
    "df['log_reg_preds'] = np.exp(df['ln_log_reg_preds'])-1\n",
    "df_merge = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(row):\n",
    "    for c in df_merge.iloc[:,2:-2].columns:\n",
    "        if row[c]==1:\n",
    "            return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173217, 32)\n"
     ]
    }
   ],
   "source": [
    "df_merge['country'] = df_merge.iloc[:,1:-2].apply(get_country, axis=1)\n",
    "df_merge['country'].fillna('United Kingdom', inplace=True)\n",
    "df_final_v2 = df_final.merge(df_merge[['days','country','log_reg_preds']], how='left', on=['days', 'country'])\n",
    "df_final_v2['StringencyIndex'].fillna(method='ffill', inplace=True)\n",
    "print(df_final_v2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"dash/df_final.csv\", index=False)\n",
    "df_final_v2.to_csv(\"dash/df_final_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df_final_v2[df_final_v2.days < 30][['date','country','max_pop','beta','actual_cases','projected_infections','log_reg_preds']].melt(id_vars = ['date', 'country','max_pop','beta'], var_name = 'projection')\n",
    "px.line(df_filt[(df_filt.country == 'United Kingdom') & (df_filt.max_pop == 0.5) & (df_filt.beta == 0.2)],\n",
    "        x='date', y='value', color='projection' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df_final_v2[df_final_v2.days < 30][['date','country','max_pop','beta', 'StringencyIndex']].melt(id_vars = ['date', 'country','max_pop','beta'], var_name = 'projection')\n",
    "px.line(df_filt[(df_filt.country == 'United Kingdom') & (df_filt.max_pop == 0.5) & (df_filt.beta == 0.2)],\n",
    "        x='date', y='value', color='projection' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
